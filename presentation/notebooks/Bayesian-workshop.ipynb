{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bayesian workshop\n",
    "***\n",
    "April 29, 2020\n",
    "\n",
    "## Mojtaba & Nikki\n",
    "***\n",
    "\n",
    "\n",
    "<!-- <img src=\"../images/Logo-GDD.png\" width=\"250\" align=\"right\"> -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What we learn today?\n",
    "- Learning and Being able to apply Bayes' Theorem\n",
    "- Hands-on session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayesian whaaat?\n",
    "***\n",
    "\n",
    "<H6> In statistics there are basically two paradigms: </H6>\n",
    "\n",
    "1. Frequentist (\"classical\" statistics, the stuff you did at school)\n",
    "2. <font color='green'>Bayesian</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why all the buzz?\n",
    "***\n",
    "\n",
    "- Bayesian statistics is very useful to express uncertainty\n",
    "- Works well with missing data and small samples\n",
    "- Bayesian allows to incorporate prior knowledge in your models\n",
    " - For example, domain knowledge\n",
    "- **Everything** in Bayesian statistics has a probability distribution\n",
    "\n",
    "The bad news?\n",
    "\n",
    "- Takes some time to get used to\n",
    "- Computations are expensive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why Bayesian statistics?\n",
    "***\n",
    "\n",
    "> Bayesian statistics is what all the cool kids are talking about these days.\n",
    "\n",
    "- Uber open-sourced Pyro (Bayesian modeling)\n",
    "- Facebook open-sourced Prophet (Bayesian forecasting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classical Hypothesis testing\n",
    "\n",
    "<img src=\"../../presentation/images/hypothesis_testing.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayesian theorem\n",
    "***\n",
    "<img src=\"../images/bayes_theorem.jpg\" width=\"400\">\n",
    "\n",
    "- it allows us to use some knowledge or belief that we already have (commonly known as the prior) to help us calculate the probability of a related event!\n",
    "- P(A|B) is the conditional probability that event A occurs given that event B has already occurred (P(B|A) has the same meaning but with the roles of A and B reversed\n",
    "- P(A) and P(B) are the marginal probabilities of event A and event B occurring respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### simple example\n",
    "***\n",
    "<H5> There are 52 cards in the pack, 26 of them are red and 26 are black. What is the probability of the card being a 4 given that we know the card is red? </H5>\n",
    "\n",
    "<img src=\"../../presentation/images/cards.png\" width=\"200\" align=\"right\">\n",
    "\n",
    "\n",
    "$$ P(4|red) = \\frac{P(red|4)P(4)}{P(red)} = \\frac{\\frac{1}{2} \\times \\frac{4}{52}}{\\frac{1}{2}} \\approx 0.07 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T12:05:10.042785Z",
     "start_time": "2020-04-27T12:05:10.022281Z"
    }
   },
   "source": [
    "## _Bayes' Theorem applied to modeling_ ##\n",
    "***\n",
    "\n",
    "Bayes' Theorem (for continuous variables) states that\n",
    "\n",
    "$$ f(x \\mid y) = \\frac{f(y \\mid x)f(x)}{f(y)}. $$\n",
    "\n",
    "This can be applied in the context of modeling data as follows (replace $x$ with $\\color{red}{\\text{model}}$ and $y$ with $\\color{green}{\\text{data}})$.\n",
    "\n",
    "$$ f(\\color{red}{\\text{model}} \\mid \\color{green}{\\text{data}} ) = \\frac{f(\\color{green}{\\text{data}} \\mid \\color{red}{\\text{model}} )\\times f(\\color{red}{\\text{model}})}{f(\\color{green}{\\text{data}})}. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Example: Flipping coins_ ## \n",
    "***\n",
    "\n",
    "![inline](../images/euro-coin-news.png)\n",
    "\n",
    "Source: https://www.newscientist.com/article/dn1748-euro-coin-accused-of-unfair-flipping/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T12:10:31.699825Z",
     "start_time": "2020-04-27T12:10:31.693251Z"
    }
   },
   "source": [
    "### Is the coin fair?\n",
    "***\n",
    "\n",
    "> Let's say you flip a euro coin 10 times and you observe 4 heads. Is the coin fair? A reasonable estimate of the probability of throwing heads is:\n",
    ">\n",
    "> $$\\hat{\\theta} = \\frac{\\text{number of heads}}{\\text{total number of flips}} = \\frac{4}{10}$$\n",
    ">\n",
    "> How **certain** are you? When would **you** be convinced that the coin is fair? What if you have reason to believe **a priori** that the coin is unfair?\n",
    "\n",
    "This is where Bayes' Theorem proves useful. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coin flipping: the Bayesian way\n",
    "***\n",
    "\n",
    "Let's use Bayes' Theorem analyze the fairness of a coin. In the context of the Bayes' formula:\n",
    "\n",
    "- The $\\color{red}{\\text{model}}$ here only consists of one parameter, namely: $\\theta$ (the probability of landing heads).  \n",
    "- The $\\color{green}{\\text{data}}$ that we observe is the number of heads (4) out of the number of coin flips (10). \n",
    "\n",
    "We consider the three components of Bayes' formula separately:\n",
    "\n",
    "#### 1. The likelihood distribution: $f(\\color{green}{\\text{data}} \\mid \\color{red}{\\text{model}} )$\n",
    "***\n",
    "\n",
    "The function $f(\\color{green}{\\text{data}} \\mid \\color{red}{\\text{model}} )$ is called the **likelihood**: it indicates how *likely* the data is, given your model. In this case, it's the probability that you observe 4 heads out of 10 coin flips, given some value for $\\theta$.\n",
    "\n",
    "**Q1:** What is the probability of seeing 4 heads out of 10 coinflips, when the probability of landing heads is equal to $\\theta$? Compute the likelihood of seeing 4 heads out of 10 coinflips for $\\theta=0.4$ and for $\\theta=0.1$. Compare the two: does it make sense what you see? \n",
    "\n",
    "\n",
    "#### 2. The prior distribution: $f(\\color{red}{\\text{model}} )$\n",
    "***\n",
    "\n",
    "The function $f(\\color{red}{\\text{model}})$ is called the **prior distribution**. It's the *belief* that we have about the fairness of coin *prior* to observing the data. Observe that it does not depend on the $\\color{green}{\\text{data}}$.\n",
    "\n",
    "**Q2:** What is a reasonable *prior* belief for a coin? Is there reason to believe that the coin is unfair?\n",
    "\n",
    "Analogous to the prior distribution, we call $f(\\color{red}{\\text{model}} \\mid \\color{green}{\\text{data}} )$ the **posterior distribution**, this is the *belief* in the model **after** (post) observation the data.\n",
    "\n",
    "\n",
    "#### 3. Specifying $f(\\color{green}{\\text{data}} )$\n",
    "***\n",
    "\n",
    "Good news: in practice, you almost never need to compute this component. \n",
    "\n",
    "**Q3:** Can you think of reasons why?\n",
    "\n",
    "\n",
    "#### Summarizing\n",
    "***\n",
    "\n",
    "The prior belief is combined with the data through the likelihood function:\n",
    "\n",
    "<img src=\"../images/bayes-flow.png\" width=\"250\">\n",
    "\n",
    "[source](http://jason-doll.com/wordpress/?page_id=127)\n",
    "\n",
    "The **posterior** distribution is what we are after: it reveals how likely certain parameter values of the model are. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T13:22:17.264139Z",
     "start_time": "2020-04-27T13:22:17.237452Z"
    }
   },
   "source": [
    "#### Answers\n",
    "***\n",
    "**Q1:** ${10\\choose 4} \\times \\theta^4 \\times (1-\\theta)^6$.\n",
    "\n",
    "Example for three coin tosses:\n",
    "![inline](../images/tree.png)\n",
    "\n",
    "**Q2:** This is a subjective matter. What do we know about $\\theta$ before seeing any data? At least, we know that $0\\leq \\theta \\leq1$ (why?). If we haven’t flipped any coins yet, we don’t know much else: so it seems logical that all values of $\\theta$ within this interval are equally likely, i.e., $f(\\theta)=1$, for all $0\\leq \\theta \\leq1$. This is known as an *uninformative prior*, because it contains little information.\n",
    "\n",
    "<img src=\"../images/uniform.png\" width=\"500\">\n",
    "\n",
    "**Q3:** Some intuition. Say you compare two models: \"model 1\" and \"model 2\". Then:\n",
    "\n",
    "$$ \\frac{f(\\color{red}{\\text{model 1}} \\mid \\color{green}{\\text{data}} )}{f(\\color{red}{\\text{model 2}} \\mid \\color{green}{\\text{data}} )}$$\n",
    "\n",
    "is a measure for how more \"likely\" model 1 is than model 2. By using Bayes' Theorem, we find that:\n",
    "\n",
    "$$\\frac{f(\\color{red}{\\text{model 1}} \\mid \\color{green}{\\text{data}} )}{f(\\color{red}{\\text{model 2}} \\mid \\color{green}{\\text{data}} )} = \\frac{\\frac{f(\\color{green}{\\text{data}} \\mid \\color{red}{\\text{model 1}} )\\times f(\\color{red}{\\text{model 1}})}{f(\\color{green}{\\text{data}})}}{\\frac{f(\\color{green}{\\text{data}} \\mid \\color{red}{\\text{model 2}} )\\times f(\\color{red}{\\text{model 2}})}{f(\\color{green}{\\text{data}})}} = \\frac{f(\\color{green}{\\text{data}} \\mid \\color{red}{\\text{model 1}} )\\times f(\\color{red}{\\text{model 1}})}{ f(\\color{green}{\\text{data}} \\mid \\color{red}{\\text{model 2}} )\\times f(\\color{red}{\\text{model 2}})} $$\n",
    "\n",
    "**Observation** This does not depend on $f(\\color{green}{\\text{data}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise (cont'd): Credibility intervals\n",
    "***\n",
    "\n",
    "**Q4:** Compute and plot the posterior, using a uniform prior distribution (we still consider the example with **10** coin flips and **4** heads).\n",
    "\n",
    "**Q5:** How certain are you that the probability of landing heads is below 60%?\n",
    "\n",
    "**Q6:** Compute the 95% **credibility interval** (this it the interval that contains the 95% most likely values).ipynb_checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T07:20:40.136253Z",
     "start_time": "2020-04-29T07:20:40.131951Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load answers/answer_Q4.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:26:33.710778Z",
     "start_time": "2020-04-27T18:26:33.708624Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load answers/answer_Q5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:26:34.393053Z",
     "start_time": "2020-04-27T18:26:34.390948Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load answers/answer_Q6.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise (cont'd): The effect of observing more data\n",
    "***\n",
    "Change `n_heads` and `n_flips` in the code above and re-run the code a few times to make plots.\n",
    "\n",
    "- What do you see?\n",
    "- What happens when you put `n_flips` higher?\n",
    "- Does this make sense?\n",
    "\n",
    "**Optional:** Wrap the code above in a function where `n_heads` and `n_flips` are parameters. Name the function `plot_posterior`. \n",
    "\n",
    "**Optional:** Make the plot interactive by using the `interact` method from `ipywidgets`:\n",
    "\n",
    "```\n",
    "from ipywidgets import interact\n",
    "interact(plot_posterior, n_flips=(1, 1000), n_heads=(1, 1000))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T07:21:00.217244Z",
     "start_time": "2020-04-29T07:21:00.213037Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load answers/plot_posterior.py\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.special import binom\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting settings\n",
    "sns.set()\n",
    "\n",
    "\n",
    "def plot_posterior(n_flips, n_heads):\n",
    "\n",
    "    # We will plot the posterior for theta = 0.00, 0.01, ..., 0.99, 1.00\n",
    "    theta = np.linspace(0, 1, 101)\n",
    "\n",
    "    # Uniform prior distribution\n",
    "    prior_distribution = np.ones(len(theta))\n",
    "\n",
    "    # Compute the likelihood\n",
    "    likelihood = theta ** n_heads * (1 - theta) ** (n_flips - n_heads)\n",
    "\n",
    "    # Posterior distribution\n",
    "    posterior = likelihood * prior_distribution\n",
    "\n",
    "    # Normalize the posterior distribution (for comparability)\n",
    "    posterior /= np.max(posterior)\n",
    "\n",
    "    _, ax = plt.subplots(figsize=(6,3))\n",
    "    ax.plot(theta, posterior)\n",
    "    ax.set_xlabel(\"Theta\", size=15)\n",
    "    ax.set_ylabel(\"Posterior value\", size=15)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_posterior(100, 50)\n",
    "\n",
    "\n",
    "from ipywidgets import interact\n",
    "interact(plot_posterior, n_flips=np.arange(5, 50, 5), n_heads=np.arange(5, 50, 5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise (cont'd): Informative prior distribution\n",
    "***\n",
    "\n",
    "Rewrite the prior distribution to reflect your prior belief that you are \n",
    "\n",
    "- 90\\% sure that $\\theta$ is between 0.3 and 0.7\n",
    "- 5\\% sure that $\\theta$ is between 0.0 and 0.3\n",
    "- 5\\% sure that $\\theta$ is between 0.7 and 1.0\n",
    "\n",
    "This is called an **informative** prior distribution, since it expresses specific information about the coin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:30:45.157416Z",
     "start_time": "2020-04-27T18:30:45.155319Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load exercises/informative_prior.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approporiate distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T13:52:31.089745Z",
     "start_time": "2020-04-27T13:52:31.082091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_11142645935902964265() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            \n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_11142645935902964265()\">Toggle show/hide</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "import random\n",
    "\n",
    "def hide_toggle(for_next=False):\n",
    "    this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
    "    next_cell = this_cell + '.next()'\n",
    "\n",
    "    toggle_text = 'Toggle show/hide'  # text shown on toggle link\n",
    "    target_cell = this_cell  # target cell to control with toggle\n",
    "    js_hide_current = ''  # bit of JS to permanently hide code in current cell (only when toggling next cell)\n",
    "\n",
    "    if for_next:\n",
    "        target_cell = next_cell\n",
    "        toggle_text += ' next cell'\n",
    "        js_hide_current = this_cell + '.find(\"div.input\").hide();'\n",
    "\n",
    "    js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
    "\n",
    "    html = \"\"\"\n",
    "        <script>\n",
    "            function {f_name}() {{\n",
    "                {cell_selector}.find('div.input').toggle();\n",
    "            }}\n",
    "\n",
    "            {js_hide_current}\n",
    "        </script>\n",
    "\n",
    "        <a href=\"javascript:{f_name}()\">{toggle_text}</a>\n",
    "    \"\"\".format(\n",
    "        f_name=js_f_name,\n",
    "        cell_selector=target_cell,\n",
    "        js_hide_current=js_hide_current, \n",
    "        toggle_text=toggle_text\n",
    "    )\n",
    "\n",
    "    return HTML(html)\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing an appropriate distribution\n",
    "***\n",
    "\n",
    "The follling decision tree, can provide you some guidance on what an appropriate distribution might be for your data.\n",
    "<img src=\"../images/distribution-flow-chart.png\" width=\"800\">\n",
    "\n",
    "[source](https://www.prioritysystem.com/reasons5c.html)\n",
    "\n",
    "**Note** however, that there are many more distributions than the ones depicted in the figure. It's a **non-exhaustive** overview."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Bayesian bandit\n",
    "***\n",
    "The multi-armed bandit (MAB) is a classic problem in decision sciences. Effectively, it is one of optimal resource allocation under uncertainty. The name is derived from old slot machines that where operated by pulling an arm — they are called bandits because they rob those who play them. \n",
    "\n",
    "<img src=\"../../presentation/images/multi-arm.png\" width=\"400\">\n",
    "\n",
    "<H5> Problem definition: </H5>\n",
    "we have different assets which we want to show on our awesome website but we really don’t know which one to show. \n",
    "<img src=\"../../presentation/images/red_blue_green.jpeg\" width=\"200\" align=\"right\">\n",
    "\n",
    "- one asset is blue(B),\n",
    "- one asset is red(R),\n",
    "- one asser is green (G)\n",
    "\n",
    "<H5> The answer is </H5>\n",
    "The win probability of blue(B) is 0.3, red(R) is 0.8 and green(G) is 0.4.\n",
    "\n",
    "\n",
    "<H5> Strategy </H5>\n",
    "$$ P(\\color{red}{\\theta} \\mid \\color{green}{\\text{data}} ) \\approx P(\\color{green}{\\text{data}} \\mid \\color{red}{\\theta} )\\times P(\\color{red}{\\theta}), $$\n",
    "\n",
    "\n",
    "1. We will sample a random variable from each of the 3 distributions for assets\n",
    "2. We will find out which random variable is maximum and will show the one asset which gave the maximum random variable\n",
    "3. We will get to know if the asset is clicked or not\n",
    "4. We will update the prior for the asset using the information in step 3.\n",
    "5. Repeat!\n",
    "\n",
    "<H5> Thompson sampling </H5>\n",
    "<img src=\"../../presentation/images/thompson-sampling.png\" width=\"300\" align=\"left\">\n",
    "\n",
    "<img src=\"../../presentation/images/bandit.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
